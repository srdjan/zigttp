//! Performance Instrumentation Module
//!
//! Provides timing and statistics collection for compilation and runtime.
//! All instrumentation is conditional on compile-time flags to zero-out overhead when disabled.
//!
//! Usage:
//!   const perf = @import("perf.zig");
//!
//!   // Compilation timing
//!   var stats = perf.CompileStats{};
//!   const timer = perf.Timer.start();
//!   // ... do work ...
//!   stats.parse_ns = timer.read();

const std = @import("std");

/// Compile-time flag to enable performance statistics collection.
/// Set to false in production builds to eliminate all overhead.
pub const enable_perf_stats = true;

/// Compile-time flag to enable opcode profiling.
/// More expensive than basic stats, disabled by default.
pub const enable_opcode_profiling = true;

// ============================================================================
// Timer - High-resolution timing utility
// ============================================================================

pub const Timer = struct {
    start_time: ?std.time.Instant,

    pub fn start() Timer {
        return .{
            .start_time = std.time.Instant.now() catch null,
        };
    }

    /// Read elapsed nanoseconds since start
    pub fn read(self: Timer) u64 {
        const start_instant = self.start_time orelse return 0;
        const now = std.time.Instant.now() catch return 0;
        return now.since(start_instant);
    }

    /// Read and reset timer
    pub fn lap(self: *Timer) u64 {
        const elapsed = self.read();
        self.start_time = std.time.Instant.now() catch self.start_time;
        return elapsed;
    }
};

// ============================================================================
// Compilation Statistics
// ============================================================================

pub const CompileStats = struct {
    /// Time spent tokenizing source code
    tokenize_ns: u64 = 0,
    /// Time spent parsing tokens to IR
    parse_ns: u64 = 0,
    /// Time spent in scope analysis
    scope_ns: u64 = 0,
    /// Time spent generating bytecode
    codegen_ns: u64 = 0,
    /// Time spent in bytecode optimization (peephole pass)
    optimize_ns: u64 = 0,
    /// Total compilation time (may include other overhead)
    total_ns: u64 = 0,

    /// Number of allocations during compilation
    alloc_count: u64 = 0,
    /// Bytes allocated during compilation
    alloc_bytes: u64 = 0,

    /// Source code size in bytes
    source_bytes: u64 = 0,
    /// Generated bytecode size in bytes
    bytecode_bytes: u64 = 0,
    /// Number of IR nodes created
    node_count: u64 = 0,
    /// Number of constants in pool
    constant_count: u64 = 0,

    /// Whether bytecode was loaded from cache
    cache_hit: bool = false,

    pub fn totalCompileNs(self: CompileStats) u64 {
        if (self.total_ns > 0) return self.total_ns;
        return self.tokenize_ns + self.parse_ns + self.scope_ns + self.codegen_ns + self.optimize_ns;
    }

    pub fn print(self: CompileStats) void {
        const stdout = std.fs.File.stdout();
        self.printToFile(stdout);
    }

    pub fn printToFile(self: CompileStats, file: std.fs.File) void {
        var buf: [256]u8 = undefined;

        file.writeAll("\n=== Compilation Statistics ===\n") catch {};
        if (self.cache_hit) {
            file.writeAll("Cache hit: yes (skipped compilation)\n") catch {};
            return;
        }

        const total = self.totalCompileNs();

        const tok_msg = std.fmt.bufPrint(&buf, "Tokenize:  {d:.3} ms ({d:.1}%)\n", .{
            @as(f64, @floatFromInt(self.tokenize_ns)) / 1_000_000.0,
            if (total > 0) @as(f64, @floatFromInt(self.tokenize_ns)) * 100.0 / @as(f64, @floatFromInt(total)) else 0.0,
        }) catch return;
        file.writeAll(tok_msg) catch {};

        const parse_msg = std.fmt.bufPrint(&buf, "Parse:     {d:.3} ms ({d:.1}%)\n", .{
            @as(f64, @floatFromInt(self.parse_ns)) / 1_000_000.0,
            if (total > 0) @as(f64, @floatFromInt(self.parse_ns)) * 100.0 / @as(f64, @floatFromInt(total)) else 0.0,
        }) catch return;
        file.writeAll(parse_msg) catch {};

        const scope_msg = std.fmt.bufPrint(&buf, "Scope:     {d:.3} ms ({d:.1}%)\n", .{
            @as(f64, @floatFromInt(self.scope_ns)) / 1_000_000.0,
            if (total > 0) @as(f64, @floatFromInt(self.scope_ns)) * 100.0 / @as(f64, @floatFromInt(total)) else 0.0,
        }) catch return;
        file.writeAll(scope_msg) catch {};

        const cg_msg = std.fmt.bufPrint(&buf, "Codegen:   {d:.3} ms ({d:.1}%)\n", .{
            @as(f64, @floatFromInt(self.codegen_ns)) / 1_000_000.0,
            if (total > 0) @as(f64, @floatFromInt(self.codegen_ns)) * 100.0 / @as(f64, @floatFromInt(total)) else 0.0,
        }) catch return;
        file.writeAll(cg_msg) catch {};

        if (self.optimize_ns > 0) {
            const opt_msg = std.fmt.bufPrint(&buf, "Optimize:  {d:.3} ms ({d:.1}%)\n", .{
                @as(f64, @floatFromInt(self.optimize_ns)) / 1_000_000.0,
                if (total > 0) @as(f64, @floatFromInt(self.optimize_ns)) * 100.0 / @as(f64, @floatFromInt(total)) else 0.0,
            }) catch return;
            file.writeAll(opt_msg) catch {};
        }

        const total_msg = std.fmt.bufPrint(&buf, "Total:     {d:.3} ms\n", .{
            @as(f64, @floatFromInt(total)) / 1_000_000.0,
        }) catch return;
        file.writeAll(total_msg) catch {};

        if (self.source_bytes > 0) {
            const src_msg = std.fmt.bufPrint(&buf, "\nSource:    {d} bytes\n", .{self.source_bytes}) catch return;
            file.writeAll(src_msg) catch {};

            const bc_msg = std.fmt.bufPrint(&buf, "Bytecode:  {d} bytes ({d:.1}x)\n", .{
                self.bytecode_bytes,
                if (self.source_bytes > 0) @as(f64, @floatFromInt(self.bytecode_bytes)) / @as(f64, @floatFromInt(self.source_bytes)) else 0.0,
            }) catch return;
            file.writeAll(bc_msg) catch {};

            const nodes_msg = std.fmt.bufPrint(&buf, "Nodes:     {d}\n", .{self.node_count}) catch return;
            file.writeAll(nodes_msg) catch {};

            const const_msg = std.fmt.bufPrint(&buf, "Constants: {d}\n", .{self.constant_count}) catch return;
            file.writeAll(const_msg) catch {};
        }
    }

    /// Merge another stats struct into this one (for aggregating across multiple compiles)
    pub fn merge(self: *CompileStats, other: CompileStats) void {
        self.tokenize_ns += other.tokenize_ns;
        self.parse_ns += other.parse_ns;
        self.scope_ns += other.scope_ns;
        self.codegen_ns += other.codegen_ns;
        self.optimize_ns += other.optimize_ns;
        self.total_ns += other.total_ns;
        self.alloc_count += other.alloc_count;
        self.alloc_bytes += other.alloc_bytes;
        self.source_bytes += other.source_bytes;
        self.bytecode_bytes += other.bytecode_bytes;
        self.node_count += other.node_count;
        self.constant_count += other.constant_count;
    }
};

// ============================================================================
// Runtime/Execution Statistics
// ============================================================================

pub const RuntimeStats = struct {
    /// Time spent executing bytecode
    exec_ns: u64 = 0,
    /// Number of bytecode instructions executed
    instruction_count: u64 = 0,
    /// Number of function calls
    call_count: u64 = 0,
    /// Number of property accesses
    property_access_count: u64 = 0,

    pub fn print(self: RuntimeStats) void {
        const stdout = std.fs.File.stdout();
        self.printToFile(stdout);
    }

    pub fn printToFile(self: RuntimeStats, file: std.fs.File) void {
        var buf: [256]u8 = undefined;

        file.writeAll("\n=== Runtime Statistics ===\n") catch {};

        const exec_msg = std.fmt.bufPrint(&buf, "Execution: {d:.3} ms\n", .{
            @as(f64, @floatFromInt(self.exec_ns)) / 1_000_000.0,
        }) catch return;
        file.writeAll(exec_msg) catch {};

        if (self.instruction_count > 0) {
            const inst_msg = std.fmt.bufPrint(&buf, "Instructions: {d}\n", .{self.instruction_count}) catch return;
            file.writeAll(inst_msg) catch {};

            const mips = @as(f64, @floatFromInt(self.instruction_count)) / (@as(f64, @floatFromInt(self.exec_ns)) / 1_000_000_000.0) / 1_000_000.0;
            const tput_msg = std.fmt.bufPrint(&buf, "Throughput: {d:.1} MIPS\n", .{mips}) catch return;
            file.writeAll(tput_msg) catch {};
        }

        if (self.call_count > 0) {
            const call_msg = std.fmt.bufPrint(&buf, "Function calls: {d}\n", .{self.call_count}) catch return;
            file.writeAll(call_msg) catch {};
        }
    }
};

// ============================================================================
// Opcode Profiling
// ============================================================================

pub const OpcodeProfile = struct {
    counts: [256]u64 = [_]u64{0} ** 256,
    total: u64 = 0,

    /// Increment counter for an opcode (inlined for minimal overhead)
    pub inline fn record(self: *OpcodeProfile, opcode: u8) void {
        if (comptime enable_opcode_profiling) {
            self.counts[opcode] += 1;
            self.total += 1;
        }
    }

    /// Get top N opcodes by frequency
    pub fn topN(self: *const OpcodeProfile, comptime N: usize) [N]OpcodeFreq {
        var result: [N]OpcodeFreq = [_]OpcodeFreq{.{}} ** N;

        for (self.counts, 0..) |count, opcode| {
            if (count == 0) continue;

            // Find insertion point
            var insert_idx: usize = N;
            for (result, 0..) |entry, i| {
                if (count > entry.count) {
                    insert_idx = i;
                    break;
                }
            }

            // Shift and insert
            if (insert_idx < N) {
                var j: usize = N - 1;
                while (j > insert_idx) : (j -= 1) {
                    result[j] = result[j - 1];
                }
                result[insert_idx] = .{
                    .opcode = @intCast(opcode),
                    .count = count,
                };
            }
        }

        return result;
    }

    pub fn print(self: *const OpcodeProfile) void {
        const stdout = std.fs.File.stdout();
        self.printToFile(stdout);
    }

    pub fn printToFile(self: *const OpcodeProfile, file: std.fs.File) void {
        const bytecode = @import("bytecode.zig");
        var buf: [256]u8 = undefined;

        file.writeAll("\n=== Opcode Profile (top 20) ===\n") catch {};

        const total_msg = std.fmt.bufPrint(&buf, "Total instructions: {d}\n\n", .{self.total}) catch return;
        file.writeAll(total_msg) catch {};

        const top = self.topN(20);
        for (top) |entry| {
            if (entry.count == 0) break;

            const name = bytecode.Opcode.name(@enumFromInt(entry.opcode));
            const pct = @as(f64, @floatFromInt(entry.count)) * 100.0 / @as(f64, @floatFromInt(self.total));
            const line = std.fmt.bufPrint(&buf, "{s:<20} {d:>12} ({d:.1}%)\n", .{ name, entry.count, pct }) catch continue;
            file.writeAll(line) catch {};
        }
    }

    pub fn reset(self: *OpcodeProfile) void {
        self.counts = [_]u64{0} ** 256;
        self.total = 0;
    }
};

pub const OpcodeFreq = struct {
    opcode: u8 = 0,
    count: u64 = 0,
};

// ============================================================================
// GC Statistics
// ============================================================================

pub const GCStats = struct {
    /// Number of minor (nursery) collections
    minor_count: u64 = 0,
    /// Number of major (full) collections
    major_count: u64 = 0,
    /// Total time spent in minor GC
    minor_ns: u64 = 0,
    /// Total time spent in major GC
    major_ns: u64 = 0,
    /// Bytes copied during minor GC
    bytes_copied: u64 = 0,
    /// Bytes swept during major GC
    bytes_swept: u64 = 0,
    /// Peak heap size
    peak_heap_bytes: u64 = 0,
    /// Current heap size
    current_heap_bytes: u64 = 0,

    pub fn print(self: GCStats) void {
        const stdout = std.fs.File.stdout();
        self.printToFile(stdout);
    }

    pub fn printToFile(self: GCStats, file: std.fs.File) void {
        var buf: [256]u8 = undefined;

        file.writeAll("\n=== GC Statistics ===\n") catch {};

        const minor_msg = std.fmt.bufPrint(&buf, "Minor GC:  {d} collections, {d:.3} ms total\n", .{
            self.minor_count,
            @as(f64, @floatFromInt(self.minor_ns)) / 1_000_000.0,
        }) catch return;
        file.writeAll(minor_msg) catch {};

        const major_msg = std.fmt.bufPrint(&buf, "Major GC:  {d} collections, {d:.3} ms total\n", .{
            self.major_count,
            @as(f64, @floatFromInt(self.major_ns)) / 1_000_000.0,
        }) catch return;
        file.writeAll(major_msg) catch {};

        if (self.bytes_copied > 0 or self.bytes_swept > 0) {
            const copied_msg = std.fmt.bufPrint(&buf, "Copied:    {d} KB\n", .{self.bytes_copied / 1024}) catch return;
            file.writeAll(copied_msg) catch {};

            const swept_msg = std.fmt.bufPrint(&buf, "Swept:     {d} KB\n", .{self.bytes_swept / 1024}) catch return;
            file.writeAll(swept_msg) catch {};
        }

        if (self.peak_heap_bytes > 0) {
            const heap_msg = std.fmt.bufPrint(&buf, "Peak heap: {d} KB\n", .{self.peak_heap_bytes / 1024}) catch return;
            file.writeAll(heap_msg) catch {};
        }
    }

    pub fn merge(self: *GCStats, other: GCStats) void {
        self.minor_count += other.minor_count;
        self.major_count += other.major_count;
        self.minor_ns += other.minor_ns;
        self.major_ns += other.major_ns;
        self.bytes_copied += other.bytes_copied;
        self.bytes_swept += other.bytes_swept;
        if (other.peak_heap_bytes > self.peak_heap_bytes) {
            self.peak_heap_bytes = other.peak_heap_bytes;
        }
    }
};

// ============================================================================
// Combined Performance Report
// ============================================================================

pub const PerfReport = struct {
    compile: CompileStats = .{},
    runtime: RuntimeStats = .{},
    gc: GCStats = .{},
    opcodes: OpcodeProfile = .{},

    pub fn print(self: *const PerfReport) void {
        const stdout = std.fs.File.stdout();
        self.printToFile(stdout);
    }

    pub fn printToFile(self: *const PerfReport, file: std.fs.File) void {
        self.compile.printToFile(file);
        self.runtime.printToFile(file);
        self.gc.printToFile(file);
        if (enable_opcode_profiling and self.opcodes.total > 0) {
            self.opcodes.printToFile(file);
        }
    }

    /// Export as JSON for programmatic analysis
    pub fn toJsonBuf(self: *const PerfReport, buf: []u8) ![]const u8 {
        const json_template =
            \\{{"compile":{{"tokenize_ns":{d},"parse_ns":{d},"scope_ns":{d},"codegen_ns":{d},"optimize_ns":{d},"total_ns":{d},"source_bytes":{d},"bytecode_bytes":{d},"cache_hit":{s}}},"runtime":{{"exec_ns":{d},"instruction_count":{d}}},"gc":{{"minor_count":{d},"major_count":{d},"minor_ns":{d},"major_ns":{d}}}}}
        ;

        const result = std.fmt.bufPrint(buf, json_template, .{
            self.compile.tokenize_ns,
            self.compile.parse_ns,
            self.compile.scope_ns,
            self.compile.codegen_ns,
            self.compile.optimize_ns,
            self.compile.totalCompileNs(),
            self.compile.source_bytes,
            self.compile.bytecode_bytes,
            if (self.compile.cache_hit) "true" else "false",
            self.runtime.exec_ns,
            self.runtime.instruction_count,
            self.gc.minor_count,
            self.gc.major_count,
            self.gc.minor_ns,
            self.gc.major_ns,
        }) catch return error.BufferTooSmall;

        return result;
    }
};

// ============================================================================
// Inline Cache Statistics
// ============================================================================

pub const ICStats = struct {
    /// Total IC lookups attempted
    lookups: u64 = 0,
    /// Successful IC hits
    hits: u64 = 0,
    /// IC misses (fallback to slow path)
    misses: u64 = 0,

    pub inline fn recordHit(self: *ICStats) void {
        self.lookups += 1;
        self.hits += 1;
    }

    pub inline fn recordMiss(self: *ICStats) void {
        self.lookups += 1;
        self.misses += 1;
    }

    pub fn hitRate(self: ICStats) f64 {
        if (self.lookups == 0) return 0.0;
        return @as(f64, @floatFromInt(self.hits)) / @as(f64, @floatFromInt(self.lookups));
    }

    pub fn printToFile(self: ICStats, file: std.fs.File) void {
        var buf: [256]u8 = undefined;

        file.writeAll("\n=== Inline Cache Statistics ===\n") catch {};

        const lookups_msg = std.fmt.bufPrint(&buf, "Lookups: {d}\n", .{self.lookups}) catch return;
        file.writeAll(lookups_msg) catch {};

        const hits_msg = std.fmt.bufPrint(&buf, "Hits:    {d} ({d:.1}%)\n", .{ self.hits, self.hitRate() * 100.0 }) catch return;
        file.writeAll(hits_msg) catch {};

        const misses_msg = std.fmt.bufPrint(&buf, "Misses:  {d}\n", .{self.misses}) catch return;
        file.writeAll(misses_msg) catch {};
    }
};

// ============================================================================
// Tests
// ============================================================================

test "Timer basic usage" {
    const timer = Timer.start();
    // Just verify timer starts and reads without error
    const elapsed = timer.read();
    // Elapsed should be small (just the time to call read)
    try std.testing.expect(elapsed < 1_000_000_000); // Less than 1 second
}

test "CompileStats totalCompileNs" {
    var stats = CompileStats{
        .tokenize_ns = 1_000_000,
        .parse_ns = 2_000_000,
        .codegen_ns = 1_500_000,
    };

    try std.testing.expectEqual(@as(u64, 4_500_000), stats.totalCompileNs());

    // When total_ns is set, it should be returned instead
    stats.total_ns = 5_000_000;
    try std.testing.expectEqual(@as(u64, 5_000_000), stats.totalCompileNs());
}

test "CompileStats merge" {
    var stats1 = CompileStats{
        .tokenize_ns = 1_000_000,
        .parse_ns = 2_000_000,
    };

    const stats2 = CompileStats{
        .tokenize_ns = 500_000,
        .parse_ns = 1_000_000,
    };

    stats1.merge(stats2);

    try std.testing.expectEqual(@as(u64, 1_500_000), stats1.tokenize_ns);
    try std.testing.expectEqual(@as(u64, 3_000_000), stats1.parse_ns);
}

test "OpcodeProfile topN" {
    var profile = OpcodeProfile{};
    profile.counts[0x10] = 100; // get_loc
    profile.counts[0x20] = 50; // add
    profile.counts[0x30] = 200; // push_const
    profile.total = 350;

    const top = profile.topN(3);
    try std.testing.expectEqual(@as(u8, 0x30), top[0].opcode);
    try std.testing.expectEqual(@as(u64, 200), top[0].count);
    try std.testing.expectEqual(@as(u8, 0x10), top[1].opcode);
    try std.testing.expectEqual(@as(u8, 0x20), top[2].opcode);
}

test "PerfReport JSON output" {
    var report = PerfReport{};
    report.compile.parse_ns = 1_000_000;
    report.runtime.exec_ns = 5_000_000;

    var buf: [1024]u8 = undefined;
    const json = try report.toJsonBuf(&buf);

    try std.testing.expect(std.mem.indexOf(u8, json, "\"parse_ns\":1000000") != null);
    try std.testing.expect(std.mem.indexOf(u8, json, "\"exec_ns\":5000000") != null);
}

test "ICStats hitRate" {
    var stats = ICStats{};
    stats.recordHit();
    stats.recordHit();
    stats.recordMiss();

    try std.testing.expectEqual(@as(u64, 3), stats.lookups);
    try std.testing.expectEqual(@as(u64, 2), stats.hits);
    try std.testing.expectEqual(@as(u64, 1), stats.misses);

    // Hit rate should be ~0.666
    const rate = stats.hitRate();
    try std.testing.expect(rate > 0.65 and rate < 0.68);
}
